{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837a707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import codecs\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LR = 0.001\n",
    "EPOCHES = 1\n",
    "BATCH_SIZE = 256\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cfd8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        data = pd.read_csv(csv_file)\n",
    "        self.X = np.array(data.iloc[:, 1:]).reshape(-1, 1, 28, 28).astype(float)\n",
    "        self.Y = np.array(data.iloc[:, 0])\n",
    "        del data\n",
    "        self.len = len(self.X)\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "     \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.X[idx]\n",
    "        label = self.Y[idx]\n",
    "        return (item, label)\n",
    "\n",
    "    \n",
    "train_dataset = FashionMNISTDataset(csv_file=  \"fashion-mnist_train.csv\")\n",
    "test_dataset = FashionMNISTDataset(csv_file=  \"fashion-mnist_isok.csv\")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e853eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(5, 5), padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(5 * 5 * 64, 10)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.layer1(x))\n",
    "        out = self.pool2(self.layer3(self.layer2(out)))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "cnn=CNN()\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948e1c0e",
   "metadata": {},
   "source": [
    "def data_write_csv(\"submission.csv\", datas):#file_name为写入CSV文件的路径，datas为要写入数据列表\n",
    "    file_csv = codecs.open(file_name,'w+','utf-8')#追加\n",
    "    writer = csv.writer(file_csv, delimiter=' ', quotechar=' ', quoting=csv.QUOTE_MINIMAL)\n",
    "    for data in datas:\n",
    "        writer.writerow(data)\n",
    "    print(\"保存文件成功，处理结束\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d297662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/1, Iter : 100/234, Loss : 0.3736\n",
      "Epoch : 1/1, Iter : 200/234, Loss : 0.2860\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(EPOCHES):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.float().to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.cpu().data.item())\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch : %d/%d, Iter : %d/%d, Loss : %.4f' % (\n",
    "                epoch + 1, EPOCHES,\n",
    "                i + 1, len(train_dataset) // BATCH_SIZE,\n",
    "                loss.data.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24c8819e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 4, 3, 7, 8, 9, 7, 6, 5, 3, 9, 4, 4, 5, 8, 8, 0, 6, 9, 9, 6, 0, 4,\n",
      "        8, 3, 8, 9, 5, 1, 0, 9, 5, 8, 8, 6, 5, 0, 6, 4, 5, 0, 4, 1, 8, 2, 3, 4,\n",
      "        2, 0, 4, 6, 8, 9, 6, 3, 9, 1, 1, 0, 6, 5, 8, 0, 6, 1, 5, 9, 5, 6, 4, 9,\n",
      "        2, 8, 9, 7, 5, 5, 7, 8, 8, 4, 4, 9, 8, 2, 2, 4, 9, 0, 3, 0, 8, 1, 9, 2,\n",
      "        9, 6, 6, 7])\n",
      "[2 0 4 3 7 8 9 7 6 5 3 9 4 4 5 8 8 0 6 9 9 6 0 4 8 3 8 9 5 1 0 9 5 8 8 6 5\n",
      " 0 6 4 5 0 4 1 8 2 3 4 2 0 4 6 8 9 6 3 9 1 1 0 6 5 8 0 6 1 5 9 5 6 4 9 2 8\n",
      " 9 7 5 5 7 8 8 4 4 9 8 2 2 4 9 0 3 0 8 1 9 2 9 6 6 7]\n",
      "CNN 测试集准确率：91.00 %\n"
     ]
    }
   ],
   "source": [
    "f = open('submission.csv', 'w',newline='', encoding='utf-8') \n",
    "csv_write = csv.writer(f)\n",
    "csv_write.writerow(['Id', 'Category'])\n",
    "\n",
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images,Id in test_loader:\n",
    "    images = images.float().to(device)\n",
    "    outputs = cnn(images).cpu()\n",
    "    _, predicted = torch.max(outputs.data, 1)#将可信度最高的编号返回，最终将这个predicted\n",
    "    abc=predicted.detach().numpy()\n",
    "    abc1=Id.detach().numpy()\n",
    "    print(abc)\n",
    "    csv_write.writerow([abc1, predicted])\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    " \n",
    "print('CNN 测试集准确率：%.2f %%' % (100 * correct / total))\n",
    "# 输出：CNN 测试集准确率：90.78 %\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5abcb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "d2l-zh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
